import streamlit as st
import google.generativeai as genai
import PyPDF2
import io

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ì‹¬ë¦¬ìƒë‹´ AI ì±—ë´‡",
    page_icon="ğŸ¤—",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

def initialize_gemini(api_key):
    genai.configure(api_key=api_key)
    return genai.GenerativeModel('gemini-pro')

def extract_text_from_pdf(pdf_file):
    pdf_reader = PyPDF2.PdfReader(pdf_file)
    text = ""
    for page in pdf_reader.pages:
        text += page.extract_text()
    return text

# ì‚¬ì´ë“œë°”ì— API í‚¤ ì…ë ¥
with st.sidebar:
    st.title("ì„¤ì •")
    api_key = st.text_input("Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")
    
    if uploaded_file:
        pdf_text = extract_text_from_pdf(uploaded_file)
        st.success("PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ë©”ì¸ í˜ì´ì§€
st.title("ğŸ¤— AI ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡")
st.write("ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”. AI ìƒë‹´ì‚¬ê°€ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")

# API í‚¤ê°€ ì…ë ¥ëœ ê²½ìš°ì—ë§Œ ì±—ë´‡ í™œì„±í™”
if api_key:
    model = initialize_gemini(api_key)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    system_prompt = """
    ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ ê²½ì²­í•˜ê³  ê³µê°í•˜ë©°, 
    ì „ë¬¸ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”. í•­ìƒ ë”°ëœ»í•˜ê³  ì§€ì§€ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ë©°,
    í•„ìš”í•œ ê²½ìš° ì „ë¬¸ê°€ ìƒë‹´ì„ ê¶Œìœ í•´ì£¼ì„¸ìš”.
    """
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            context = system_prompt
            if uploaded_file:
                context += f"\nì°¸ê³ í•  ë¬¸ì„œ ë‚´ìš©: {pdf_text}"
            
            response = model.generate_content(context + "\nì‚¬ìš©ì: " + prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})

else:
    st.warning("Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown("âš ï¸ ì´ AI ìƒë‹´ ì„œë¹„ìŠ¤ëŠ” ì „ë¬¸ ìƒë‹´ì‚¬ë¥¼ ëŒ€ì²´í•  ìˆ˜ ì—†ìœ¼ë©°, ì‹¬ê°í•œ ì‹¬ë¦¬ì  ì–´ë ¤ì›€ì´ ìˆëŠ” ê²½ìš° ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
